{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nama : Andreas Hendra Herwanto\n",
    "### NIM  : 164221064"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scraping 1 halaman website unair news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\t\t\t\tWebsvaganza 2023 Hadirkan Bazar Kosmetik untuk Dorong Kepercayaan Diri dan Hilangkan Insecure\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\tMahasiswa UNAIR Sabet Juara 1 Kategori Lomba Infografis KOMINFO Jawa Timur\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\tPentingnya Mengenal Potensi Diri Melalui Pemahaman Emosional\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\tDukung Pendidikan Merata UNAIR Berikan Beasiswa Siswa Sekolah Dasar\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\tApa Sih UKM Wanala ?\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\tAncam Boikot SpaceX, Dosen UNAIR Sebut Israel Tidak Ingin Aksi Genosida Diketahui Dunia Luar\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\tDr Andriyanto, Alumnus UNAIR yang Dilantik Menjadi Pj Bupati Pasuruan\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\tKisah Mahasiswa UNAIR Eksplor Kanada Melalui IISMA di University of Waterloo\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\tPerjalanan Menantang Mahasiswa UNAIR Ikuti IISMA di University of Szeged Hungaria\t\t\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "response = requests.get('https://unair.ac.id/news')\n",
    "rawhtml = response.text\n",
    "soup = BeautifulSoup (rawhtml, 'html.parser')\n",
    "\n",
    "for i in soup.find_all('h2'):\n",
    "    print(i.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kode di atas digunakan untuk scraping 1 halaman website UNAIR News. Langkah-langkahnya adalah sebagai berikut:\n",
    "\n",
    "1. Import library `requests` dan `BeautifulSoup`.\n",
    "2. Lakukan permintaan GET ke URL 'https://unair.ac.id/news' menggunakan `requests.get` dan simpan responsenya di variabel `response`.\n",
    "3. Ambil teks respons dalam bentuk HTML dan simpan dalam variabel `rawhtml`.\n",
    "4. Gunakan `BeautifulSoup` untuk mem-parsing `rawhtml` menggunakan parser HTML bawaan dengan pernyataan `BeautifulSoup(rawhtml, 'html.parser')`, dan simpan hasilnya dalam variabel `soup`.\n",
    "5. Di sini untuk menemukan semua elemen dengan tag 'h2' dalam HTML, saya mmenggunakan loop `for`, dengan `soup.find_all('h2')` . `find_all`berfungsi untuk mencari semua elemen yang sesuai dengan kriteria tersebut. Setelah itu, di semua elemen tersebut diprint."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Crawling featured news (5 pages only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\t\t\t\tDr Andriyanto, Alumnus UNAIR yang Dilantik Menjadi Pj Bupati Pasuruan\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\tUNAIR Raih 4,5 Trees Rating pada UI GreenMetric World University Ranking\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\tPakar Politik UNAIR Sebut Pengusungan Gibran Jadi Strategi Jangka Panjang\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\tBerkomitmen Tingkatkan Transparansi Informasi, UNAIR Gabung JDIH\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\tKomitmen Tingkatkan Kualitas Pendidikan, Rektor UNAIR Kukuhkan Enam Guru Besar\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\tTambah Lagi, UNAIR Kini Miliki 11 Jurnal Ilmiah Terindeks Scopus\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\tUNAIR Raih Anugerah Jatim Bangkit Awards Berkat Sukseskan Pemulihan Pandemi\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\tKukuhkan Tujuh Guru Besar, Rektor UNAIR Ajak Akademisi Tingkatkan Daya Kritis\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\tBeri Kuliah Tamu di UNAIR, Mahfud MD Tekankan Pentingnya Politik Kebangsaan\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\tUNAIR Anugerahi Khofifah Gelar Doktor Honoris Causa\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\tUNAIR Luluskan 1.382 Wisudawan, Rektor: Anda Orang-Orang Terpilih\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\tRektor Beri Pesan Gubes untuk Bumikan Ilmu Pengetahuan\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\tUNAIR Bagikan 1974 Sertifikat Halal Gratis untuk UMKM\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\tKukuhkan Tujuh Guru Besar, Rektor UNAIR Tekankan Kerja Sama Riset Internasional\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\tUNAIR Tingkatkan Kontribusi dengan Tambah 7 Guru Besar Baru\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\tUNAIR Duduki Peringkat Kedua Nasional Versi THE WUR\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\tDukung Merdeka Belajar, UNAIR Berikan Ruang Eksplorasi Bagi Mahasiswa\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\tPengukuhan Gubes Wujudkan UNAIR Jadi SMART University\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\tJadi Tuan Rumah The 6th ASEAN+3 Rector’s Conference, UNAIR Tekankan Pentingnya Kolaborasi\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\tIntip Kisah Guru Besar UNAIR yang 18 Tahun Mengabdi Jadi Dokter Forensik\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\tKukuhkan Gubes, Rektor: Semoga Target Segera Tercapai\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\tSingkirkan Puluhan Peserta, Mahasiswa UNAIR Bawa Pulang Medali Emas\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\tJadi Pionir, FKH UNAIR Adakan Program MBKM di 10 Wilayah Jatim\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\tResmi! UNAIR Bakal Miliki Plaza Airlangga\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\tMenkes Luncurkan Permenkes Rumah Sakit Kapal, Berobat di RSTKA Kini Bisa Pakai BPJS\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\tPengukuhan Guru Besar Jadi Tambahan Energi bagi UNAIR\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\tKukuhkan Empat Guru Besar FK, Rektor UNAIR Tekankan Kecintaan pada Ilmu\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\tMasuk Deretan Top 100 Peneliti Indonesia, Wakil Rektor UNAIR Bagikan Tips bagi Peneliti Pemula\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\tUNAIR Siap Tingkatkan Kontribusi dengan 12 Guru Besar Baru\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\tUNAIR Sambut Kedatangan 390 Peserta Pertukaran Mahasiswa Merdeka\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\tJanis Rosalita, Alumnus UNAIR jadi Atlet Terbaik Putri SIWO 2023\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\tRektor UNAIR Beri Tanggapan Kebijakan Baru Penghapusan Skripsi\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\tIKA UNAIR Wilayah Inggris Gelar Silaturahmi dan Konsolidasi Alumni\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\tProduk Penurun Glukosa dalam Darah Gubes UNAIR Tembus Pameran Internasional di Pakistan\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\tMahasiswa UNAIR Ciptakan Alat Deteksi Stress pada E-Sport\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\t\t\t\tTanam Jahe dan Sereh untuk Tingkatkan Kesehatan Warga Flat Kenari\t\t\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "for i in range(1, 6):\n",
    "    url = \"https://unair.ac.id/category/featured/page/\"+str(i)+\"/\"\n",
    "    response = requests.get(url)\n",
    "    rawhtml = response.text\n",
    "    soup = BeautifulSoup(rawhtml,'html.parser')\n",
    "    for j in soup.find_all('h3'):\n",
    "        print(j.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pada kode di atas, kita akan melakukan crawling pada featured news.\n",
    "\n",
    "1. Kita mengimport library `requests` dan `BeautifulSoup`.\n",
    "2. `for i in range(1, 6)`, Featured news memiliki 290 pages, di sini saya hanyakan melakukan crawling pada 5 pages saja. \n",
    "3. Dalam setiap iterasi, kita membentuk URL sesuai dengan nomor halaman dengan memasukkan variabel `i` ke dalam URL menggunakan konversi `str(i)`. Kemudian, kita menggunakan `requests.get` untuk mengambil halaman web yang sesuai.\n",
    "4. Setelah mendapatkan responsenya, kita mengambil teks HTML-nya dan menyimpannya dalam variabel `rawhtml`.\n",
    "5. Selanjutnya, kita menggunakan `BeautifulSoup` untuk mem-parsing `rawhtml` menggunakan parser HTML bawaan dengan pernyataan `BeautifulSoup(rawhtml, 'html.parser')`, dan hasilnya disimpan dalam variabel `soup`.\n",
    "6. Dalam loop `for j`, kita menggunakan `soup.find_all('h3')` untuk menemukan semua elemen dengan tag 'h3' dalam HTML tersebut. `find_all` mengembalikan daftar semua elemen yang sesuai dengan kriteria tersebut.\n",
    "7. Dalam setiap iterasi di dalam loop `for j`, kita mencetak teks dari setiap elemen yang ditemukan menggunakan `j.get_text()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "from selenium import webdriver\n",
    "from scrapy.selector import Selector\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "\n",
    "class Webcrawling_Game(scrapy.Spider):\n",
    "    name ='andre_week8'\n",
    "    start_urls = ['https://bit.ly/scrapingtry']\n",
    "\n",
    "    def __init__(self):\n",
    "        self.driver = webdriver.ChromiumEdge()\n",
    "        self.wait = WebDriverWait(self.driver, 10)\n",
    "\n",
    "    def parse(self, response):\n",
    "        self.driver.get(response.url)\n",
    "\n",
    "        while True:\n",
    "            self.wait.until(EC.presence_of_all_elements_located(\n",
    "                (By.CSS_SELECTOR, 'span.psw-t-body.psw-c-t-1.psw-t-truncate-2.psw-m-b-2')))\n",
    "            sel = Selector(text=self.driver.page_source)\n",
    "\n",
    "            for game in sel.css('span.psw-t-body.psw-c-t-1.psw-t-truncate-2.psw-m-b-2'):\n",
    "                yield {\n",
    "                    'title': game.css('::text').get(),\n",
    "                    'price': sel.css('span.psw-m-r-3::text').get().replace('\\xa0', ' '),\n",
    "                }\n",
    "\n",
    "            try:\n",
    "                next_button = self.wait.until(EC.element_to_be_clickable(\n",
    "                    (By.CSS_SELECTOR, 'button[data-qa=\"ems-sdk-grid#ems-sdk-top-paginator-root#next\"]')))\n",
    "                self.driver.execute_script(\"arguments[0].scrollIntoView();\", next_button)\n",
    "                self.driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "\n",
    "                self.wait.until(EC.staleness_of(next_button))\n",
    "            except:\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langkah-langkah untuk running code tersebut :\n",
    "1. Install scrapy \n",
    "2. Pilih directory yang ingin digunkan untuk menyimpan file project\n",
    "3. Pada terminal, masuk ke directory tersebut lalu ketik `scrapy startproject projectname`\n",
    "4. Buka folder tersebut pada text editor, lalu masuk ke folder spider\n",
    "5. Pada folder spider, buat file .py baru dan masukan kode tersebut\n",
    "6. Kemudian pada terminal ketik `scrapy crawl andre_week8 -o game_crawl.csv`(outpunya dalam bentuk csv)\n",
    "\n",
    "\n",
    "Penjelasan dari code tersebut :\n",
    "\n",
    "1. Import library yang diperlukan: `scrapy`, `webdriver` dari Selenium, `Selector` dari Scrapy, dan beberapa modul lain yang diperlukan.\n",
    "2. Definisikan kelas `Webcrawling_Game` yang merupakan turunan dari kelas `scrapy.Spider`. Kemudian, tentukan atribut `name` dan `start_urls`.\n",
    "3. Di dalam fungsi `__init__`, inisialisasi pengendali `self.driver` untuk `ChromiumEdge` (web browser yang digunakan), dan tentukan waktu tunggu `self.wait` sebesar 10 detik.\n",
    "4. Dalam metode `parse`, buka URL yang diberikan menggunakan `self.driver.get(response.url)`.\n",
    "5. Selama perulangan tak terbatas (`while True`), tunggu hingga semua elemen yang diinginkan muncul menggunakan `self.wait.until` dengan CSS_SELECTOR yang sesuai. Kemudian, buat objek Selector dari sumber halaman dengan `Selector(text=self.driver.page_source)`.\n",
    "6. Dalam loop `for`, ambil judul dan harga game menggunakan CSS_SELECTOR yang sesuai dan tambahkan hasilnya ke dalam `yield` statement untuk disimpan.\n",
    "7. Gunakan `try` dan `except` untuk menangani tombol \"next\" dan scroll ke bawah menggunakan JavaScript jika ada, kemudian klik tombol \"next\" menggunakan `self.driver.execute_script`.\n",
    "8. Tunggu hingga halaman diperbarui menggunakan `self.wait.until(EC.staleness_of(next_button))`. Jika tidak ada lagi tombol \"next\" yang dapat diklik, keluar dari perulangan menggunakan `break`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
